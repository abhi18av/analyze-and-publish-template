// Results management utilities will be imported automatically from lib/
// Use Python script for results directory creation

params {
    // Project configuration
    project_name = 'bioinformatics_pipeline'
    workflow_type = 'analysis'  // Options: hyperopt, training, inference, analysis
    
    // Auto-generate results directory with timestamp
    timestamp = new Date().format('yyyyMMdd_HHmmss')
    base_results_dir = 'results'
    
    // Create organized results directory using Python script
    outdir = createResultsDirectory()
    
    // Default parameters
    test = "TEST"
    
    // Input/output parameters
    input = null
    publish_dir_mode = 'copy'
    
    // Resource parameters
    max_memory = '8.GB'
    max_cpus = 4
    max_time = '24.h'
}

// Function to create results directory using Python script
def createResultsDirectory() {
    def scriptPath = "${workflow.projectDir}/../scripts/results/results_manager.py"
    def cmd = ["python3", scriptPath, "create", 
               "--workflow-type", params.workflow_type,
               "--project-name", params.project_name,
               "--base-dir", params.base_results_dir]
    
    try {
        def proc = cmd.execute()
        proc.waitFor()
        if (proc.exitValue() == 0) {
            return proc.text.trim()
        } else {
            println "Warning: Could not create results directory, using default"
            return "${params.base_results_dir}/default_run"
        }
    } catch (Exception e) {
        println "Warning: Could not execute results manager script: ${e.message}"
        return "${params.base_results_dir}/default_run"
    }
}

// Configure process execution
process {
    // Publish directories based on workflow type
    publishDir = [
        [path: "${params.outdir}/01_preprocessing", mode: params.publish_dir_mode, pattern: '*_qc.*'],
        [path: "${params.outdir}/02_analysis", mode: params.publish_dir_mode, pattern: '*_results.*'],
        [path: "${params.outdir}/03_reports", mode: params.publish_dir_mode, pattern: '*.html'],
        [path: "${params.outdir}/pipeline_info", mode: params.publish_dir_mode, pattern: '.command.*']
    ]
    
    // Resource defaults
    memory = { check_max(2.GB * task.attempt, 'memory') }
    cpus = 1
    time = { check_max(4.h * task.attempt, 'time') }
    
    // Error handling
    errorStrategy = 'retry'
    maxRetries = 2
}

// Execution profiles
profiles {
    local {
        process.executor = 'local'
        process.memory = params.max_memory
        process.cpus = params.max_cpus
    }
    
    docker {
        docker.enabled = true
        process.container = 'ubuntu:20.04'
    }
    
    singularity {
        singularity.enabled = true
        process.container = 'ubuntu:20.04'
    }
    
    hyperopt {
        params.workflow_type = 'hyperopt'
        process.memory = { check_max(4.GB * task.attempt, 'memory') }
        process.cpus = { check_max(2 * task.attempt, 'cpus') }
        process.publishDir = [
            [path: "${params.outdir}/01_data_preparation", mode: params.publish_dir_mode, pattern: '*_qc.*'],
            [path: "${params.outdir}/02_optimization/trials", mode: params.publish_dir_mode, pattern: 'trial_*'],
            [path: "${params.outdir}/02_optimization", mode: params.publish_dir_mode, pattern: 'best_parameters.*'],
            [path: "${params.outdir}/03_validation", mode: params.publish_dir_mode, pattern: '*_validation.*'],
            [path: "${params.outdir}/04_reports", mode: params.publish_dir_mode, pattern: '*.html']
        ]
    }
    
    training {
        params.workflow_type = 'training'
        process.memory = { check_max(8.GB * task.attempt, 'memory') }
        process.cpus = { check_max(4 * task.attempt, 'cpus') }
        process.publishDir = [
            [path: "${params.outdir}/01_preprocessing", mode: params.publish_dir_mode, pattern: '*_preprocessed.*'],
            [path: "${params.outdir}/02_model_training", mode: params.publish_dir_mode, pattern: '*_model.*'],
            [path: "${params.outdir}/03_evaluation", mode: params.publish_dir_mode, pattern: '*_evaluation.*'],
            [path: "${params.outdir}/04_reports", mode: params.publish_dir_mode, pattern: '*.html']
        ]
    }
    
    inference {
        params.workflow_type = 'inference'
        process.memory = { check_max(4.GB * task.attempt, 'memory') }
        process.cpus = { check_max(2 * task.attempt, 'cpus') }
        process.publishDir = [
            [path: "${params.outdir}/01_input_processing", mode: params.publish_dir_mode, pattern: '*_processed.*'],
            [path: "${params.outdir}/02_predictions", mode: params.publish_dir_mode, pattern: '*_predictions.*'],
            [path: "${params.outdir}/03_quality_control", mode: params.publish_dir_mode, pattern: '*_qc.*'],
            [path: "${params.outdir}/04_reports", mode: params.publish_dir_mode, pattern: '*.html']
        ]
    }
}

// Tower configuration
tower {
    accessToken = System.getenv('TOWER_ACCESS_TOKEN')
    enabled = System.getenv('TOWER_ACCESS_TOKEN') ? true : false
}

// Resource checking function
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Workflow completion handler
workflow.onComplete {
    // Update run status using Python script
    def scriptPath = "${workflow.projectDir}/../scripts/results/results_manager.py"
    def status = workflow.success ? 'completed' : 'failed'
    def cmd = ["python3", scriptPath, "update-status", params.outdir, status]
    
    try {
        def proc = cmd.execute()
        proc.waitFor()
    } catch (Exception e) {
        println "Warning: Could not update run status: ${e.message}"
    }
    
    // Create execution summary
    def summary = [:]
    summary['Pipeline Name'] = workflow.manifest.name ?: 'Unknown'
    summary['Pipeline Version'] = workflow.manifest.version ?: 'Unknown'
    summary['Run Name'] = workflow.runName
    summary['Workflow Type'] = params.workflow_type
    summary['Results Directory'] = params.outdir
    summary['Completed at'] = workflow.complete
    summary['Duration'] = workflow.duration
    summary['Success'] = workflow.success
    summary['Exit code'] = workflow.exitStatus
    summary['Error report'] = workflow.errorReport ?: 'None'
    
    // Write execution summary
    def summaryFile = new File("${params.outdir}/pipeline_info/execution_summary.txt")
    summaryFile.parentFile.mkdirs()
    summaryFile.text = summary.collect { k, v -> "${k.padRight(20)}: $v" }.join('\n')
    
    println """
    Pipeline execution completed!
    
    Results directory: ${params.outdir}
    Status: ${status}
    Duration: ${workflow.duration}
    
    Latest results available at: ${params.base_results_dir}/latest/${params.workflow_type}
    """.stripIndent()
}
