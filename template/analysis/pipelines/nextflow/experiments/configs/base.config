// Base configuration for Nextflow experiments
// This file contains common settings for all experiment runs

// Enable resume by default (can be overridden)
resume = true

// Process configuration
process {
    // Default resource allocation
    cpus = 2
    memory = '4.GB'
    time = '6.h'
    
    // Error handling for resumable experiments
    errorStrategy = 'retry'
    maxRetries = 2
    
    // Container settings (if using containers)
    container = 'ubuntu:20.04'
    
    // Process-specific configurations
    withName: 'validate_data' {
        cpus = 1
        memory = '2.GB'
        time = '1.h'
    }
    
    withName: 'clean_data' {
        cpus = 2
        memory = '4.GB'
        time = '2.h'
    }
    
    withName: 'feature_engineering' {
        cpus = 4
        memory = '8.GB'
        time = '4.h'
    }
    
    withName: 'quality_assessment' {
        cpus = 2
        memory = '4.GB'
        time = '2.h'
    }
}

// Execution settings
executor {
    // Default to local execution
    name = 'local'
    cpus = 8
    memory = '32.GB'
}

// Reports and tracing
timeline {
    enabled = true
    file = "${params.output_dir}/reports/timeline.html"
}

report {
    enabled = true
    file = "${params.output_dir}/reports/report.html"
}

trace {
    enabled = true
    file = "${params.output_dir}/reports/trace.txt"
    fields = 'task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes,vol_ctxt_swch,inv_ctxt_swch'
}

dag {
    enabled = true
    file = "${params.output_dir}/reports/dag.svg"
}

// Work directory settings
workDir = './work'

// Tower integration
tower {
    enabled = true
    accessToken = System.getenv('TOWER_ACCESS_TOKEN')
    workspaceId = System.getenv('TOWER_WORKSPACE_ID')
}

// Manifest information
manifest {
    name = 'Data Processing Pipeline'
    author = 'Research Team'
    homePage = 'https://github.com/your-org/your-pipeline'
    description = 'Academic data processing pipeline with resume support'
    version = '1.0.0'
    nextflowVersion = '>=21.04.0'
}

// Parameter defaults
params {
    // Input/Output
    input = null
    output_dir = './results'
    
    // Pipeline options
    help = false
    resume = true
    
    // Resource limits
    max_cpus = 16
    max_memory = '64.GB'
    max_time = '24.h'
    
    // Publishing options
    publish_mode = 'copy'
    
    // Experiment tracking
    experiment_id = null
    researcher = 'unknown'
    project = 'data-analysis'
}
